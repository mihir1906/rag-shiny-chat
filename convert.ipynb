{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def trim_md(txt: str) -> str:\n",
    "    start_idx = txt.find(\"# \")\n",
    "    end_idx = txt.find(\"[Previ\")\n",
    "    if start_idx > 0:\n",
    "        return (\n",
    "            txt[start_idx:end_idx]\n",
    "            .strip(\"\\n\")\n",
    "            .replace(\" Python Rust\", \"\")\n",
    "            .replace(\"·\", \"\")\n",
    "        )\n",
    "    else:\n",
    "        return txt\n",
    "\n",
    "\n",
    "def process_code_blocks(txt: str) -> str:\n",
    "    matches = re.findall(\"```[^`]*```\", txt)\n",
    "    for match in matches:\n",
    "        if \"shape\" in match or \"cargo\" in match or \";\" in match:\n",
    "            txt = txt.replace(match, \"\")\n",
    "        else:\n",
    "            new_block = f\"```python\\n{match[3:]}\"\n",
    "            txt = txt.replace(match, new_block)\n",
    "    return txt\n",
    "\n",
    "\n",
    "def remove_links(txt: str) -> str:\n",
    "    matches = re.findall(\"[[]`?[^`]*`?[]][(][^(]*[)]\", txt)\n",
    "    for match in matches:\n",
    "        txt = txt.replace(match, \"\")\n",
    "    return txt\n",
    "\n",
    "\n",
    "# def chunk_md(txt:str)->list[str]:\n",
    "#     chunks=[]\n",
    "#     in_chunk=False\n",
    "#     for line in txt.split(\"\\n\"):\n",
    "#         if line.startswith(\"#\")\n",
    "\n",
    "# return re.split(\"^#.*$\",txt,flags=re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is bad user-guide/lazy/optimizations/index.html\n",
      "this is bad user-guide/transformations/joins/index.html\n",
      "this is bad user-guide/sql/intro/index.html\n",
      "this is bad user-guide/expressions/missing-data/index.html\n",
      "user-guide/expressions/lists/index.html\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from markdownify import markdownify as md\n",
    "\n",
    "save_o = \"\"\n",
    "for file in Path(\"user-guide\").rglob(\"*html\"):\n",
    "    if \"basic\" in str(file):\n",
    "        continue\n",
    "    # print(file)\n",
    "    with open(file, \"r\") as f:\n",
    "        file_content = f.read()\n",
    "    output = md(file_content, heading_style=\"ATX\")\n",
    "    new_path = Path(\"converted\") / (\"/\".join(str(file).split(\"/\")[1:])[:-4] + \"md\")\n",
    "    # print(new_path)\n",
    "    Path(new_path.parent).mkdir(parents=True, exist_ok=True)\n",
    "    new_output = remove_links(process_code_blocks(trim_md(output)))\n",
    "    if \";\" in new_output:\n",
    "        if \"lists\" in str(file):\n",
    "            print(str(file))\n",
    "            save_o = output\n",
    "            break\n",
    "        print(\"this is bad\", file)\n",
    "\n",
    "    continue\n",
    "    with open(new_path, \"w\") as new_f:\n",
    "        new_f.write(output)\n",
    "\n",
    "# file_path = \"user-guide/getting-started/index.html\"\n",
    "# with open(file_path, 'r') as file:\n",
    "#     file_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "save_o = trim_md(save_o)\n",
    "matches = re.findall(\"```[^`]*```\", save_o)\n",
    "for match in matches:\n",
    "    if \"temps_rank\" in match:\n",
    "        pprint.pprint(match)\n",
    "\n",
    "# pprint.pprint(save_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# Lists and Arrays\\n'\n",
      " 'Polars has first-class support for `List` columns: that is, columns where '\n",
      " 'each row is a list of homogeneous elements, of varying lengths. Polars also '\n",
      " \"has an `Array` datatype, which is analogous to NumPy's `ndarray` objects, \"\n",
      " 'where the length is identical across rows.\\n'\n",
      " \"Note: this is different from Python's `list` object, where the elements can \"\n",
      " 'be of any type. Polars can store these within columns, but as a generic '\n",
      " \"`Object` datatype that doesn't have the special list manipulation features \"\n",
      " \"that we're about to discuss.\\n\"\n",
      " '## Powerful `List` manipulation\\n'\n",
      " \"Let's say we had the following data from different weather stations across a \"\n",
      " 'state. When the weather station is unable to get a result, an error code is '\n",
      " 'recorded instead of the actual temperature at that time.\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`DataFrame`](https://docs.pola.rs/py-polars/html/reference/dataframe/index.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'weather = pl.DataFrame(\\n'\n",
      " '    {\\n'\n",
      " '        \"station\": [\"Station \" + str(x) for x in range(1, 6)],\\n'\n",
      " '        \"temperatures\": [\\n'\n",
      " '            \"20 5 5 E1 7 13 19 9 6 20\",\\n'\n",
      " '            \"18 8 16 11 23 E2 8 E2 E2 E2 90 70 40\",\\n'\n",
      " '            \"19 24 E9 16 6 12 10 22\",\\n'\n",
      " '            \"E2 E0 15 7 8 10 E1 24 17 13 6\",\\n'\n",
      " '            \"14 8 E0 16 22 24 E1\",\\n'\n",
      " '        ],\\n'\n",
      " '    }\\n'\n",
      " ')\\n'\n",
      " 'print(weather)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`DataFrame`](https://docs.pola.rs/docs/rust/dev/polars/frame/struct.DataFrame.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'let stns: Vec<String> = (1..6).map(|i| format!(\"Station {i}\")).collect();\\n'\n",
      " 'let weather = df!(\\n'\n",
      " '        \"station\"=> &stns,\\n'\n",
      " '        \"temperatures\"=> &[\\n'\n",
      " '            \"20 5 5 E1 7 13 19 9 6 20\",\\n'\n",
      " '            \"18 8 16 11 23 E2 8 E2 E2 E2 90 70 40\",\\n'\n",
      " '            \"19 24 E9 16 6 12 10 22\",\\n'\n",
      " '            \"E2 E0 15 7 8 10 E1 24 17 13 6\",\\n'\n",
      " '            \"14 8 E0 16 22 24 E1\",\\n'\n",
      " '        ],\\n'\n",
      " ')?;\\n'\n",
      " 'println!(\"{}\", &weather);\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'shape: (5, 2)\\n'\n",
      " '┌───────────┬─────────────────────────────────┐\\n'\n",
      " '│ station   ┆ temperatures                    │\\n'\n",
      " '│ ---       ┆ ---                             │\\n'\n",
      " '│ str       ┆ str                             │\\n'\n",
      " '╞═══════════╪═════════════════════════════════╡\\n'\n",
      " '│ Station 1 ┆ 20 5 5 E1 7 13 19 9 6 20        │\\n'\n",
      " '│ Station 2 ┆ 18 8 16 11 23 E2 8 E2 E2 E2 90… │\\n'\n",
      " '│ Station 3 ┆ 19 24 E9 16 6 12 10 22          │\\n'\n",
      " '│ Station 4 ┆ E2 E0 15 7 8 10 E1 24 17 13 6   │\\n'\n",
      " '│ Station 5 ┆ 14 8 E0 16 22 24 E1             │\\n'\n",
      " '└───────────┴─────────────────────────────────┘\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '### Creating a `List` column\\n'\n",
      " \"For the `weather` `DataFrame` created above, it's very likely we need to run \"\n",
      " 'some analysis on the temperatures that are captured by each station. To make '\n",
      " 'this happen, we need to first be able to get individual temperature '\n",
      " 'measurements. This is done by:\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`str.split`](https://docs.pola.rs/py-polars/html/reference/expressions/api/polars.Expr.str.split.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'out = weather.with_columns(pl.col(\"temperatures\").str.split(\" \"))\\n'\n",
      " 'print(out)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`str.split`](https://docs.pola.rs/docs/rust/dev/polars_lazy/dsl/string/struct.StringNameSpace.html#method.split)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'let out = weather\\n'\n",
      " '    .clone()\\n'\n",
      " '    .lazy()\\n'\n",
      " '    .with_columns([col(\"temperatures\").str().split(lit(\" \"))])\\n'\n",
      " '    .collect()?;\\n'\n",
      " 'println!(\"{}\", &out);\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'shape: (5, 2)\\n'\n",
      " '┌───────────┬──────────────────────┐\\n'\n",
      " '│ station   ┆ temperatures         │\\n'\n",
      " '│ ---       ┆ ---                  │\\n'\n",
      " '│ str       ┆ list[str]            │\\n'\n",
      " '╞═══════════╪══════════════════════╡\\n'\n",
      " '│ Station 1 ┆ [\"20\", \"5\", … \"20\"]  │\\n'\n",
      " '│ Station 2 ┆ [\"18\", \"8\", … \"40\"]  │\\n'\n",
      " '│ Station 3 ┆ [\"19\", \"24\", … \"22\"] │\\n'\n",
      " '│ Station 4 ┆ [\"E2\", \"E0\", … \"6\"]  │\\n'\n",
      " '│ Station 5 ┆ [\"14\", \"8\", … \"E1\"]  │\\n'\n",
      " '└───────────┴──────────────────────┘\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " 'One way we could go post this would be to convert each temperature '\n",
      " 'measurement into its own row:\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`DataFrame.explode`](https://docs.pola.rs/py-polars/html/reference/dataframe/api/polars.DataFrame.explode.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'out = weather.with_columns(pl.col(\"temperatures\").str.split(\" \")).explode(\\n'\n",
      " '    \"temperatures\"\\n'\n",
      " ')\\n'\n",
      " 'print(out)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`DataFrame.explode`](https://docs.pola.rs/docs/rust/dev/polars/frame/struct.DataFrame.html#method.explode)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'let out = weather\\n'\n",
      " '    .clone()\\n'\n",
      " '    .lazy()\\n'\n",
      " '    .with_columns([col(\"temperatures\").str().split(lit(\" \"))])\\n'\n",
      " '    .explode([\"temperatures\"])\\n'\n",
      " '    .collect()?;\\n'\n",
      " 'println!(\"{}\", &out);\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'shape: (49, 2)\\n'\n",
      " '┌───────────┬──────────────┐\\n'\n",
      " '│ station   ┆ temperatures │\\n'\n",
      " '│ ---       ┆ ---          │\\n'\n",
      " '│ str       ┆ str          │\\n'\n",
      " '╞═══════════╪══════════════╡\\n'\n",
      " '│ Station 1 ┆ 20           │\\n'\n",
      " '│ Station 1 ┆ 5            │\\n'\n",
      " '│ Station 1 ┆ 5            │\\n'\n",
      " '│ Station 1 ┆ E1           │\\n'\n",
      " '│ Station 1 ┆ 7            │\\n'\n",
      " '│ …         ┆ …            │\\n'\n",
      " '│ Station 5 ┆ E0           │\\n'\n",
      " '│ Station 5 ┆ 16           │\\n'\n",
      " '│ Station 5 ┆ 22           │\\n'\n",
      " '│ Station 5 ┆ 24           │\\n'\n",
      " '│ Station 5 ┆ E1           │\\n'\n",
      " '└───────────┴──────────────┘\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " 'However, in Polars, we often do not need to do this to operate on the `List` '\n",
      " 'elements.\\n'\n",
      " '### Operating on `List` columns\\n'\n",
      " 'Polars provides several standard operations on `List` columns. If we want '\n",
      " 'the first three measurements, we can do a `head(3)`. The last three can be '\n",
      " 'obtained via a `tail(3)`, or alternately, via `slice` (negative indexing is '\n",
      " 'supported). We can also identify the number of observations via `lengths`. '\n",
      " \"Let's see them in action:\\n\"\n",
      " '\\n'\n",
      " ' '\n",
      " '[`Expr.list`](https://docs.pola.rs/py-polars/html/reference/expressions/list.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'out = weather.with_columns(pl.col(\"temperatures\").str.split(\" '\n",
      " '\")).with_columns(\\n'\n",
      " '    pl.col(\"temperatures\").list.head(3).alias(\"top3\"),\\n'\n",
      " '    pl.col(\"temperatures\").list.slice(-3, 3).alias(\"bottom_3\"),\\n'\n",
      " '    pl.col(\"temperatures\").list.len().alias(\"obs\"),\\n'\n",
      " ')\\n'\n",
      " 'print(out)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`Expr.list`](https://docs.pola.rs/docs/rust/dev/polars_lazy/dsl/struct.ListNameSpace.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'let out = weather\\n'\n",
      " '    .clone()\\n'\n",
      " '    .lazy()\\n'\n",
      " '    .with_columns([col(\"temperatures\").str().split(lit(\" \"))])\\n'\n",
      " '    .with_columns([\\n'\n",
      " '        col(\"temperatures\").list().head(lit(3)).alias(\"top3\"),\\n'\n",
      " '        col(\"temperatures\")\\n'\n",
      " '            .list()\\n'\n",
      " '            .slice(lit(-3), lit(3))\\n'\n",
      " '            .alias(\"bottom_3\"),\\n'\n",
      " '        col(\"temperatures\").list().len().alias(\"obs\"),\\n'\n",
      " '    ])\\n'\n",
      " '    .collect()?;\\n'\n",
      " 'println!(\"{}\", &out);\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'shape: (5, 5)\\n'\n",
      " '┌───────────┬──────────────────────┬────────────────────┬────────────────────┬─────┐\\n'\n",
      " '│ station   ┆ temperatures         ┆ top3               ┆ bottom_3           '\n",
      " '┆ obs │\\n'\n",
      " '│ ---       ┆ ---                  ┆ ---                ┆ ---                '\n",
      " '┆ --- │\\n'\n",
      " '│ str       ┆ list[str]            ┆ list[str]          ┆ list[str]          '\n",
      " '┆ u32 │\\n'\n",
      " '╞═══════════╪══════════════════════╪════════════════════╪════════════════════╪═════╡\\n'\n",
      " '│ Station 1 ┆ [\"20\", \"5\", … \"20\"]  ┆ [\"20\", \"5\", \"5\"]   ┆ [\"9\", \"6\", \"20\"]   '\n",
      " '┆ 10  │\\n'\n",
      " '│ Station 2 ┆ [\"18\", \"8\", … \"40\"]  ┆ [\"18\", \"8\", \"16\"]  ┆ [\"90\", \"70\", \"40\"] '\n",
      " '┆ 13  │\\n'\n",
      " '│ Station 3 ┆ [\"19\", \"24\", … \"22\"] ┆ [\"19\", \"24\", \"E9\"] ┆ [\"12\", \"10\", \"22\"] '\n",
      " '┆ 8   │\\n'\n",
      " '│ Station 4 ┆ [\"E2\", \"E0\", … \"6\"]  ┆ [\"E2\", \"E0\", \"15\"] ┆ [\"17\", \"13\", \"6\"]  '\n",
      " '┆ 11  │\\n'\n",
      " '│ Station 5 ┆ [\"14\", \"8\", … \"E1\"]  ┆ [\"14\", \"8\", \"E0\"]  ┆ [\"22\", \"24\", \"E1\"] '\n",
      " '┆ 7   │\\n'\n",
      " '└───────────┴──────────────────────┴────────────────────┴────────────────────┴─────┘\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '`arr` then, `list` now\\n'\n",
      " 'If you find references to the `arr` API on Stackoverflow or other sources, '\n",
      " 'just replace `arr` with `list`, this was the old accessor for the `List` '\n",
      " 'datatype. `arr` now refers to the newly introduced `Array` datatype (see '\n",
      " 'below).\\n'\n",
      " '\\n'\n",
      " '### Element-wise computation within `List`s\\n'\n",
      " 'If we need to identify the stations that are giving the most number of '\n",
      " 'errors from the starting `DataFrame`, we need to:\\n'\n",
      " '1. Parse the string input as a `List` of string values (already done).\\n'\n",
      " '2. Identify those strings that can be converted to numbers.\\n'\n",
      " '3. Identify the number of non-numeric values (i.e. `null` values) in the '\n",
      " 'list, by row.\\n'\n",
      " '4. Rename this output as `errors` so that we can easily identify the '\n",
      " 'stations.\\n'\n",
      " 'The third step requires a casting (or alternately, a regex pattern search) '\n",
      " 'operation to be perform on each element of the list. We can do this using by '\n",
      " 'applying the operation on each element by first referencing them in the '\n",
      " '`pl.element()` context, and then calling a suitable Polars expression on '\n",
      " \"them. Let's see how:\\n\"\n",
      " '\\n'\n",
      " ' '\n",
      " '[`Expr.list`](https://docs.pola.rs/py-polars/html/reference/expressions/list.html)  '\n",
      " '[`element`](https://docs.pola.rs/py-polars/html/reference/expressions/api/polars.element.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'out = weather.with_columns(\\n'\n",
      " '    pl.col(\"temperatures\")\\n'\n",
      " '    .str.split(\" \")\\n'\n",
      " '    .list.eval(pl.element().cast(pl.Int64, strict=False).is_null())\\n'\n",
      " '    .list.sum()\\n'\n",
      " '    .alias(\"errors\")\\n'\n",
      " ')\\n'\n",
      " 'print(out)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`Expr.list`](https://docs.pola.rs/docs/rust/dev/polars_lazy/dsl/struct.ListNameSpace.html)  '\n",
      " '[`element`](https://docs.pola.rs/docs/rust/dev/polars_lazy/dsl/fn.col.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'let out = weather\\n'\n",
      " '    .clone()\\n'\n",
      " '    .lazy()\\n'\n",
      " '    .with_columns([col(\"temperatures\")\\n'\n",
      " '        .str()\\n'\n",
      " '        .split(lit(\" \"))\\n'\n",
      " '        .list()\\n'\n",
      " '        .eval(col(\"\").cast(DataType::Int64).is_null(), false)\\n'\n",
      " '        .list()\\n'\n",
      " '        .sum()\\n'\n",
      " '        .alias(\"errors\")])\\n'\n",
      " '    .collect()?;\\n'\n",
      " 'println!(\"{}\", &out);\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'shape: (5, 3)\\n'\n",
      " '┌───────────┬─────────────────────────────────┬────────┐\\n'\n",
      " '│ station   ┆ temperatures                    ┆ errors │\\n'\n",
      " '│ ---       ┆ ---                             ┆ ---    │\\n'\n",
      " '│ str       ┆ str                             ┆ u32    │\\n'\n",
      " '╞═══════════╪═════════════════════════════════╪════════╡\\n'\n",
      " '│ Station 1 ┆ 20 5 5 E1 7 13 19 9 6 20        ┆ 1      │\\n'\n",
      " '│ Station 2 ┆ 18 8 16 11 23 E2 8 E2 E2 E2 90… ┆ 4      │\\n'\n",
      " '│ Station 3 ┆ 19 24 E9 16 6 12 10 22          ┆ 1      │\\n'\n",
      " '│ Station 4 ┆ E2 E0 15 7 8 10 E1 24 17 13 6   ┆ 3      │\\n'\n",
      " '│ Station 5 ┆ 14 8 E0 16 22 24 E1             ┆ 2      │\\n'\n",
      " '└───────────┴─────────────────────────────────┴────────┘\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " 'What if we chose the regex route (i.e. recognizing the presence of *any* '\n",
      " 'alphabetical character?)\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`str.contains`](https://docs.pola.rs/py-polars/html/reference/expressions/api/polars.Expr.str.contains.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'out = weather.with_columns(\\n'\n",
      " '    pl.col(\"temperatures\")\\n'\n",
      " '    .str.split(\" \")\\n'\n",
      " '    .list.eval(pl.element().str.contains(\"(?i)[a-z]\"))\\n'\n",
      " '    .list.sum()\\n'\n",
      " '    .alias(\"errors\")\\n'\n",
      " ')\\n'\n",
      " 'print(out)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`str.contains`](https://docs.pola.rs/docs/rust/dev/polars_lazy/dsl/string/struct.StringNameSpace.html#method.contains)  '\n",
      " '[Available on feature regex](/user-guide/installation/#feature-flags \"To use '\n",
      " 'this functionality enable the feature flag regex\")\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'let out = weather\\n'\n",
      " '    .clone()\\n'\n",
      " '    .lazy()\\n'\n",
      " '    .with_columns([col(\"temperatures\")\\n'\n",
      " '        .str()\\n'\n",
      " '        .split(lit(\" \"))\\n'\n",
      " '        .list()\\n'\n",
      " '        .eval(col(\"\").str().contains(lit(\"(?i)[a-z]\"), false), false)\\n'\n",
      " '        .list()\\n'\n",
      " '        .sum()\\n'\n",
      " '        .alias(\"errors\")])\\n'\n",
      " '    .collect()?;\\n'\n",
      " 'println!(\"{}\", &out);\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'shape: (5, 3)\\n'\n",
      " '┌───────────┬─────────────────────────────────┬────────┐\\n'\n",
      " '│ station   ┆ temperatures                    ┆ errors │\\n'\n",
      " '│ ---       ┆ ---                             ┆ ---    │\\n'\n",
      " '│ str       ┆ str                             ┆ u32    │\\n'\n",
      " '╞═══════════╪═════════════════════════════════╪════════╡\\n'\n",
      " '│ Station 1 ┆ 20 5 5 E1 7 13 19 9 6 20        ┆ 1      │\\n'\n",
      " '│ Station 2 ┆ 18 8 16 11 23 E2 8 E2 E2 E2 90… ┆ 4      │\\n'\n",
      " '│ Station 3 ┆ 19 24 E9 16 6 12 10 22          ┆ 1      │\\n'\n",
      " '│ Station 4 ┆ E2 E0 15 7 8 10 E1 24 17 13 6   ┆ 3      │\\n'\n",
      " '│ Station 5 ┆ 14 8 E0 16 22 24 E1             ┆ 2      │\\n'\n",
      " '└───────────┴─────────────────────────────────┴────────┘\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " \"If you're unfamiliar with the `(?i)`, it's a good time to look at the \"\n",
      " 'documentation for the `str.contains` function in Polars! The Rust regex '\n",
      " 'crate provides a lot of additional regex flags that might come in handy.\\n'\n",
      " '## Row-wise computations\\n'\n",
      " 'This context is ideal for computing in row orientation.\\n'\n",
      " 'We can apply **any** Polars operations on the elements of the list with the '\n",
      " '`list.eval` (`list().eval` in Rust) expression! These expressions run '\n",
      " \"entirely on Polars' query engine and can run in parallel, so will be well \"\n",
      " \"optimized. Let's say we have another set of weather data across three days, \"\n",
      " 'for different stations:\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`DataFrame`](https://docs.pola.rs/py-polars/html/reference/dataframe/index.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'weather_by_day = pl.DataFrame(\\n'\n",
      " '    {\\n'\n",
      " '        \"station\": [\"Station \" + str(x) for x in range(1, 11)],\\n'\n",
      " '        \"day_1\": [17, 11, 8, 22, 9, 21, 20, 8, 8, 17],\\n'\n",
      " '        \"day_2\": [15, 11, 10, 8, 7, 14, 18, 21, 15, 13],\\n'\n",
      " '        \"day_3\": [16, 15, 24, 24, 8, 23, 19, 23, 16, 10],\\n'\n",
      " '    }\\n'\n",
      " ')\\n'\n",
      " 'print(weather_by_day)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`DataFrame`](https://docs.pola.rs/docs/rust/dev/polars/frame/struct.DataFrame.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'let stns: Vec<String> = (1..11).map(|i| format!(\"Station {i}\")).collect();\\n'\n",
      " 'let weather_by_day = df!(\\n'\n",
      " '        \"station\" => &stns,\\n'\n",
      " '        \"day_1\" => &[17, 11, 8, 22, 9, 21, 20, 8, 8, 17],\\n'\n",
      " '        \"day_2\" => &[15, 11, 10, 8, 7, 14, 18, 21, 15, 13],\\n'\n",
      " '        \"day_3\" => &[16, 15, 24, 24, 8, 23, 19, 23, 16, 10],\\n'\n",
      " ')?;\\n'\n",
      " 'println!(\"{}\", &weather_by_day);\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'shape: (10, 4)\\n'\n",
      " '┌────────────┬───────┬───────┬───────┐\\n'\n",
      " '│ station    ┆ day_1 ┆ day_2 ┆ day_3 │\\n'\n",
      " '│ ---        ┆ ---   ┆ ---   ┆ ---   │\\n'\n",
      " '│ str        ┆ i64   ┆ i64   ┆ i64   │\\n'\n",
      " '╞════════════╪═══════╪═══════╪═══════╡\\n'\n",
      " '│ Station 1  ┆ 17    ┆ 15    ┆ 16    │\\n'\n",
      " '│ Station 2  ┆ 11    ┆ 11    ┆ 15    │\\n'\n",
      " '│ Station 3  ┆ 8     ┆ 10    ┆ 24    │\\n'\n",
      " '│ Station 4  ┆ 22    ┆ 8     ┆ 24    │\\n'\n",
      " '│ Station 5  ┆ 9     ┆ 7     ┆ 8     │\\n'\n",
      " '│ Station 6  ┆ 21    ┆ 14    ┆ 23    │\\n'\n",
      " '│ Station 7  ┆ 20    ┆ 18    ┆ 19    │\\n'\n",
      " '│ Station 8  ┆ 8     ┆ 21    ┆ 23    │\\n'\n",
      " '│ Station 9  ┆ 8     ┆ 15    ┆ 16    │\\n'\n",
      " '│ Station 10 ┆ 17    ┆ 13    ┆ 10    │\\n'\n",
      " '└────────────┴───────┴───────┴───────┘\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " \"Let's do something interesting, where we calculate the percentage rank of \"\n",
      " 'the temperatures by day, measured across stations. Pandas allows you to '\n",
      " \"compute the percentages of the `rank` values. Polars doesn't provide a \"\n",
      " 'special function to do this directly, but because expressions are so '\n",
      " 'versatile we can create our own percentage rank expression for highest '\n",
      " \"temperature. Let's try that!\\n\"\n",
      " '\\n'\n",
      " ' '\n",
      " '[`list.eval`](https://docs.pola.rs/py-polars/html/reference/expressions/api/polars.Expr.list.eval.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'rank_pct = (pl.element().rank(descending=True) / '\n",
      " 'pl.col(\"*\").count()).round(2)\\n'\n",
      " '\\n'\n",
      " 'out = weather_by_day.with_columns(\\n'\n",
      " '    # create the list of homogeneous data\\n'\n",
      " '    pl.concat_list(pl.all().exclude(\"station\")).alias(\"all_temps\")\\n'\n",
      " ').select(\\n'\n",
      " '    # select all columns except the intermediate list\\n'\n",
      " '    pl.all().exclude(\"all_temps\"),\\n'\n",
      " '    # compute the rank by calling `list.eval`\\n'\n",
      " '    pl.col(\"all_temps\").list.eval(rank_pct, '\n",
      " 'parallel=True).alias(\"temps_rank\"),\\n'\n",
      " ')\\n'\n",
      " '\\n'\n",
      " 'print(out)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`list.eval`](https://docs.pola.rs/docs/rust/dev/polars_lazy/dsl/trait.ListNameSpaceExtension.html#method.eval)  '\n",
      " '[Available on feature list\\\\_eval](/user-guide/installation/#feature-flags '\n",
      " '\"To use this functionality enable the feature flag list_eval\")\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'let rank_pct = (col(\"\")\\n'\n",
      " '    .rank(\\n'\n",
      " '        RankOptions {\\n'\n",
      " '            method: RankMethod::Average,\\n'\n",
      " '            descending: true,\\n'\n",
      " '        },\\n'\n",
      " '        None,\\n'\n",
      " '    )\\n'\n",
      " '    .cast(DataType::Float32)\\n'\n",
      " '    / col(\"*\").count().cast(DataType::Float32))\\n'\n",
      " '.round(2);\\n'\n",
      " '\\n'\n",
      " 'let out = weather_by_day\\n'\n",
      " '    .clone()\\n'\n",
      " '    .lazy()\\n'\n",
      " '    .with_columns(\\n'\n",
      " '        // create the list of homogeneous data\\n'\n",
      " '        [concat_list([all().exclude([\"station\"])])?.alias(\"all_temps\")],\\n'\n",
      " '    )\\n'\n",
      " '    .select(\\n'\n",
      " '        // select all columns except the intermediate list\\n'\n",
      " '        [\\n'\n",
      " '            all().exclude([\"all_temps\"]),\\n'\n",
      " '            // compute the rank by calling `list.eval`\\n'\n",
      " '            col(\"all_temps\")\\n'\n",
      " '                .list()\\n'\n",
      " '                .eval(rank_pct, true)\\n'\n",
      " '                .alias(\"temps_rank\"),\\n'\n",
      " '        ],\\n'\n",
      " '    )\\n'\n",
      " '    .collect()?;\\n'\n",
      " '\\n'\n",
      " 'println!(\"{}\", &out);\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'shape: (10, 5)\\n'\n",
      " '┌────────────┬───────┬───────┬───────┬────────────────────┐\\n'\n",
      " '│ station    ┆ day_1 ┆ day_2 ┆ day_3 ┆ temps_rank         │\\n'\n",
      " '│ ---        ┆ ---   ┆ ---   ┆ ---   ┆ ---                │\\n'\n",
      " '│ str        ┆ i64   ┆ i64   ┆ i64   ┆ list[f64]          │\\n'\n",
      " '╞════════════╪═══════╪═══════╪═══════╪════════════════════╡\\n'\n",
      " '│ Station 1  ┆ 17    ┆ 15    ┆ 16    ┆ [0.33, 1.0, 0.67]  │\\n'\n",
      " '│ Station 2  ┆ 11    ┆ 11    ┆ 15    ┆ [0.83, 0.83, 0.33] │\\n'\n",
      " '│ Station 3  ┆ 8     ┆ 10    ┆ 24    ┆ [1.0, 0.67, 0.33]  │\\n'\n",
      " '│ Station 4  ┆ 22    ┆ 8     ┆ 24    ┆ [0.67, 1.0, 0.33]  │\\n'\n",
      " '│ Station 5  ┆ 9     ┆ 7     ┆ 8     ┆ [0.33, 1.0, 0.67]  │\\n'\n",
      " '│ Station 6  ┆ 21    ┆ 14    ┆ 23    ┆ [0.67, 1.0, 0.33]  │\\n'\n",
      " '│ Station 7  ┆ 20    ┆ 18    ┆ 19    ┆ [0.33, 1.0, 0.67]  │\\n'\n",
      " '│ Station 8  ┆ 8     ┆ 21    ┆ 23    ┆ [1.0, 0.67, 0.33]  │\\n'\n",
      " '│ Station 9  ┆ 8     ┆ 15    ┆ 16    ┆ [1.0, 0.67, 0.33]  │\\n'\n",
      " '│ Station 10 ┆ 17    ┆ 13    ┆ 10    ┆ [0.33, 0.67, 1.0]  │\\n'\n",
      " '└────────────┴───────┴───────┴───────┴────────────────────┘\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '## Polars `Array`s\\n'\n",
      " '`Array`s are a new data type that was recently introduced, and are still '\n",
      " 'pretty nascent in features that it offers. The major difference between a '\n",
      " '`List` and an `Array` is that the latter is limited to having the same '\n",
      " 'number of elements per row, while a `List` can have a variable number of '\n",
      " \"elements. Both still require that each element's data type is the same.\\n\"\n",
      " 'We can define `Array` columns in this manner:\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`Array`](https://docs.pola.rs/py-polars/html/reference/api/polars.Array.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'array_df = pl.DataFrame(\\n'\n",
      " '    [\\n'\n",
      " '        pl.Series(\"Array_1\", [[1, 3], [2, 5]]),\\n'\n",
      " '        pl.Series(\"Array_2\", [[1, 7, 3], [8, 1, 0]]),\\n'\n",
      " '    ],\\n'\n",
      " '    schema={\\n'\n",
      " '        \"Array_1\": pl.Array(pl.Int64, 2),\\n'\n",
      " '        \"Array_2\": pl.Array(pl.Int64, 3),\\n'\n",
      " '    },\\n'\n",
      " ')\\n'\n",
      " 'print(array_df)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`Array`](https://docs.pola.rs/docs/rust/dev/polars/datatypes/enum.DataType.html#variant.Array)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'let mut col1: ListPrimitiveChunkedBuilder<Int32Type> =\\n'\n",
      " '    ListPrimitiveChunkedBuilder::new(\"Array_1\", 8, 8, DataType::Int32);\\n'\n",
      " 'col1.append_slice(&[1, 3]);\\n'\n",
      " 'col1.append_slice(&[2, 5]);\\n'\n",
      " 'let mut col2: ListPrimitiveChunkedBuilder<Int32Type> =\\n'\n",
      " '    ListPrimitiveChunkedBuilder::new(\"Array_2\", 8, 8, DataType::Int32);\\n'\n",
      " 'col2.append_slice(&[1, 7, 3]);\\n'\n",
      " 'col2.append_slice(&[8, 1, 0]);\\n'\n",
      " 'let array_df = DataFrame::new([col1.finish(), col2.finish()].into())?;\\n'\n",
      " '\\n'\n",
      " 'println!(\"{}\", &array_df);\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'shape: (2, 2)\\n'\n",
      " '┌───────────────┬───────────────┐\\n'\n",
      " '│ Array_1       ┆ Array_2       │\\n'\n",
      " '│ ---           ┆ ---           │\\n'\n",
      " '│ array[i64, 2] ┆ array[i64, 3] │\\n'\n",
      " '╞═══════════════╪═══════════════╡\\n'\n",
      " '│ [1, 3]        ┆ [1, 7, 3]     │\\n'\n",
      " '│ [2, 5]        ┆ [8, 1, 0]     │\\n'\n",
      " '└───────────────┴───────────────┘\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " 'Basic operations are available on it:\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`Series.arr`](https://docs.pola.rs/py-polars/html/reference/series/array.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'out = array_df.select(\\n'\n",
      " '    pl.col(\"Array_1\").arr.min().name.suffix(\"_min\"),\\n'\n",
      " '    pl.col(\"Array_2\").arr.sum().name.suffix(\"_sum\"),\\n'\n",
      " ')\\n'\n",
      " 'print(out)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " ' '\n",
      " '[`Series.arr`](https://docs.pola.rs/docs/rust/dev/polars_lazy/dsl/struct.ArrayNameSpace.html)\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'let out = array_df\\n'\n",
      " '    .clone()\\n'\n",
      " '    .lazy()\\n'\n",
      " '    .select([\\n'\n",
      " '        col(\"Array_1\").list().min().name().suffix(\"_min\"),\\n'\n",
      " '        col(\"Array_2\").list().sum().name().suffix(\"_sum\"),\\n'\n",
      " '    ])\\n'\n",
      " '    .collect()?;\\n'\n",
      " 'println!(\"{}\", &out);\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " 'shape: (2, 2)\\n'\n",
      " '┌─────────────┬─────────────┐\\n'\n",
      " '│ Array_1_min ┆ Array_2_sum │\\n'\n",
      " '│ ---         ┆ ---         │\\n'\n",
      " '│ i64         ┆ i64         │\\n'\n",
      " '╞═════════════╪═════════════╡\\n'\n",
      " '│ 1           ┆ 11          │\\n'\n",
      " '│ 2           ┆ 9           │\\n'\n",
      " '└─────────────┴─────────────┘\\n'\n",
      " '\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " 'Polars `Array`s are still being actively developed, so this section will '\n",
      " 'likely change in the future.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(save_o.replace(\"\\n\\n\\n\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "from llama_index.core.node_parser import MarkdownNodeParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"converted\", recursive=True).load_data()\n",
    "splitter = MarkdownNodeParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01287342828c4373a8abb3fcb76be7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = splitter.get_nodes_from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"/home/miky/.cache/huggingface/hub/models--BAAI--bge-small-en-v1.5/snapshots/5c38ec7c405ec4b44b94cc5a9bb96e735b38267a\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miky/env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://docs.pola.rs/user-guide/concepts/contexts/'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"converted\"\n",
    "url = \"https://docs.pola.rs/user-guide\"\n",
    "start_idx = nodes[0].metadata[\"file_path\"].find(word) + len(word)\n",
    "url + nodes[0].metadata[\"file_path\"][start_idx:-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Config',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_vars__',\n",
       " '__config__',\n",
       " '__custom_root_type__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__exclude_fields__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_validators__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__include_fields__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__json_encoder__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__post_root_validators__',\n",
       " '__pre_root_validators__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__schema_cache__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__try_update_forward_refs__',\n",
       " '__validators__',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_copy_and_set_values',\n",
       " '_decompose_class',\n",
       " '_enforce_dict_if_root',\n",
       " '_get_value',\n",
       " '_init_private_attributes',\n",
       " '_iter',\n",
       " 'as_related_node_info',\n",
       " 'child_nodes',\n",
       " 'class_name',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'embedding',\n",
       " 'end_char_idx',\n",
       " 'excluded_embed_metadata_keys',\n",
       " 'excluded_llm_metadata_keys',\n",
       " 'extra_info',\n",
       " 'from_dict',\n",
       " 'from_json',\n",
       " 'from_orm',\n",
       " 'get_content',\n",
       " 'get_embedding',\n",
       " 'get_metadata_str',\n",
       " 'get_node_info',\n",
       " 'get_text',\n",
       " 'get_type',\n",
       " 'hash',\n",
       " 'id_',\n",
       " 'json',\n",
       " 'metadata',\n",
       " 'metadata_seperator',\n",
       " 'metadata_template',\n",
       " 'mimetype',\n",
       " 'next_node',\n",
       " 'node_id',\n",
       " 'node_info',\n",
       " 'parent_node',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'prev_node',\n",
       " 'ref_doc_id',\n",
       " 'relationships',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'set_content',\n",
       " 'source_node',\n",
       " 'start_char_idx',\n",
       " 'text',\n",
       " 'text_template',\n",
       " 'to_dict',\n",
       " 'to_json',\n",
       " 'update_forward_refs',\n",
       " 'validate']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nodes[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TextNode'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[20].class_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_txt = [node.get_text() for node in nodes]\n",
    "metadata_lst = []\n",
    "word = \"converted\"\n",
    "url = \"https://docs.pola.rs/user-guide\"\n",
    "\n",
    "for node in nodes:\n",
    "    meta = node.metadata | {\"text\": node.get_text()}\n",
    "    file_path = node.metadata[\"file_path\"]\n",
    "    start_idx = file_path.find(word) + len(word)\n",
    "    link = url + file_path[start_idx:-8]\n",
    "    meta = meta | {\"link\": link}\n",
    "\n",
    "    metadata_lst.append(meta)\n",
    "\n",
    "\n",
    "# metadata_lst = [node.metadata | {\"text\":node.get_text()} | {\"link\":node.metadata[\"file_path\"][]} for node in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': '/home/miky/polars/converted/concepts/contexts/index.md',\n",
       " 'file_name': 'index.md',\n",
       " 'file_type': 'text/markdown',\n",
       " 'file_size': 3573,\n",
       " 'creation_date': '2024-06-17',\n",
       " 'last_modified_date': '2024-06-17',\n",
       " 'text': 'Contexts\\n\\n\\nPolars has developed its own Domain Specific Language (DSL) for transforming data. The language is very easy to use and allows for complex queries that remain human readable. The two core components of the language are Contexts and Expressions, the latter we will cover in the next section.\\n\\n\\nA context, as implied by the name, refers to the context in which an expression needs to be evaluated. There are three main contexts 1:\\n\\n\\n1. Selection: `df.select(...)`, `df.with_columns(...)`\\n2. Filtering: `df.filter()`\\n3. Group by / Aggregation: `df.group_by(...).agg(...)`\\n\\n\\nThe examples below are performed on the following `DataFrame`:\\n\\n\\n\\n\\n\\n \\n\\n```python\\n\\ndf = pl.DataFrame(\\n    {\\n        \"nrs\": [1, 2, 3, None, 5],\\n        \"names\": [\"foo\", \"ham\", \"spam\", \"egg\", None],\\n        \"random\": np.random.rand(5),\\n        \"groups\": [\"A\", \"A\", \"B\", \"C\", \"B\"],\\n    }\\n)\\nprint(df)\\n\\n```',\n",
       " 'link': 'https://docs.pola.rs/user-guide/concepts/contexts/'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f43bf1b71145778927777167ba6e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "embeddings = model.encode(node_txt, show_progress_bar=True, device=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323, 384)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection(\"document_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "collection_name = \"document_collection\"\n",
    "if client.collection_exists(collection_name) == False:\n",
    "    client.create_collection(\n",
    "        collection_name=\"document_collection\",\n",
    "        vectors_config=VectorParams(\n",
    "            size=model.get_sentence_embedding_dimension(), distance=Distance.COSINE\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_points(\n",
    "    collection_name=collection_name,\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=idx, vector=embeddings[idx].tolist(), payload=metadata_lst[idx]\n",
    "        )\n",
    "        for idx, doc in enumerate(documents)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'creation_date': '2024-06-17', 'file_name': 'index.md', 'file_path': '/home/miky/polars/converted/expressions/missing-data/index.md', 'file_size': 5968, 'file_type': 'text/markdown', 'last_modified_date': '2024-06-17', 'text': 'Missing data metadata\\n\\n\\nEach Arrow array used by Polars stores two kinds of metadata related to missing data. This metadata allows Polars to quickly show how many missing values there are and which values are missing.\\n\\n\\nThe first piece of metadata is the `null_count` - this is the number of rows with `null` values in the column:\\n\\n\\n\\n\\n\\n \\n\\n```python\\n\\nnull_count_df = df.null_count()\\nprint(null_count_df)\\n\\n```\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe `null_count` method can be called on a `DataFrame`, a column from a `DataFrame` or a `Series`. The `null_count` method is a cheap operation as `null_count` is already calculated for the underlying Arrow array.\\n\\n\\nThe second piece of metadata is an array called a *validity bitmap* that indicates whether each data value is valid or missing.\\nThe validity bitmap is memory efficient as it is bit encoded - each value is either a 0 or a 1. This bit encoding means the memory overhead per array is only (array length / 8) bytes. The validity bitmap is used by the `is_null` method in Polars.\\n\\n\\nYou can return a `Series` based on the validity bitmap for a column in a `DataFrame` or a `Series` with the `is_null` method:\\n\\n\\n\\n\\n\\n \\n\\n```python\\n\\nis_null_series = df.select(\\n    pl.col(\"value\").is_null(),\\n)\\nprint(is_null_series)\\n\\n```\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe `is_null` method is a cheap operation that does not require scanning the full column for `null` values. This is because the validity bitmap already exists and can be returned as a Boolean array.'} score: 0.73431176\n",
      "{'creation_date': '2024-06-17', 'file_name': 'index.md', 'file_path': '/home/miky/polars/converted/transformations/time-series/resampling/index.md', 'file_size': 2044, 'file_type': 'text/markdown', 'last_modified_date': '2024-06-17', 'text': 'Upsampling strategies\\n\\n\\nIn this example we upsample from the original 30 minutes to 15 minutes and then use a `forward` strategy to replace the nulls with the previous non-null value:\\n\\n\\n\\n\\n\\n \\n\\n```python\\n\\nout1 = df.upsample(time_column=\"time\", every=\"15m\").fill_null(strategy=\"forward\")\\nprint(out1)\\n\\n```\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIn this example we instead fill the nulls by linear interpolation:\\n\\n\\n\\n\\n\\n     \\n\\n```python\\n\\nout2 = (\\n    df.upsample(time_column=\"time\", every=\"15m\")\\n    .interpolate()\\n    .fill_null(strategy=\"forward\")\\n)\\nprint(out2)\\n\\n```'} score: 0.6794766\n",
      "{'creation_date': '2024-06-17', 'file_name': 'index.md', 'file_path': '/home/miky/polars/converted/expressions/user-defined-functions/index.md', 'file_size': 11551, 'file_type': 'text/markdown', 'last_modified_date': '2024-06-17', 'text': 'Adding a counter\\n\\n\\nIn this example we create a global `counter` and then add the integer `1` to the global state at every element processed.\\nEvery iteration the result of the increment will be added to the element value.\\n\\n\\n\\n> Note, this example isn\\'t provided in Rust. The reason is that the global `counter` value would lead to data races when this `apply` is evaluated in parallel. It would be possible to wrap it in a `Mutex` to protect the variable, but that would be obscuring the point of the example. This is a case where the Python Global Interpreter Lock\\'s performance tradeoff provides some safety guarantees.\\n\\n\\n\\n\\n\\n\\n```python\\n\\ncounter = 0\\n\\n\\ndef add_counter(val: int) -> int:\\n    global counter\\n    counter += 1\\n    return counter + val\\n\\n\\nout = df.select(\\n    pl.col(\"values\").map_elements(add_counter).alias(\"solution_map_elements\"),\\n    (pl.col(\"values\") + pl.int_range(1, pl.len() + 1)).alias(\"solution_expr\"),\\n)\\nprint(out)\\n\\n```\\n\\n\\n\\n\\n```python\\n\\n\\n\\n```python'} score: 0.65759814\n"
     ]
    }
   ],
   "source": [
    "hits = client.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=model.encode(\"Explain the null count method\").tolist(),\n",
    "    limit=3,\n",
    ")\n",
    "for hit in hits:\n",
    "    print(hit.payload, \"score:\", hit.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import Qdrant\n",
    "\n",
    "qdrant = Qdrant.from_existing_collection(\n",
    "    embedding=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    url=\"http://localhost:6333\",\n",
    "    content_payload_key=\"text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "retriever = qdrant.as_retriever(search_kwargs={\"k\": 2})\n",
    "llm = Ollama(model=\"gemma:2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant for answering questions about the Polars python library.\n",
    "You are given the following extracted parts of a long document and a question. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
    "If the question is not about Polars, politely inform them that you are tuned to only answer questions about Polars.\n",
    "Question: {input}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer in Markdown\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "query = \"Explain the null count method\"\n",
    "ans = chain.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Explain the null count method',\n",
       " 'context': [Document(page_content='Missing data metadata\\n\\n\\nEach Arrow array used by Polars stores two kinds of metadata related to missing data. This metadata allows Polars to quickly show how many missing values there are and which values are missing.\\n\\n\\nThe first piece of metadata is the `null_count` - this is the number of rows with `null` values in the column:\\n\\n\\n\\n\\n\\n \\n\\n```python\\n\\nnull_count_df = df.null_count()\\nprint(null_count_df)\\n\\n```\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe `null_count` method can be called on a `DataFrame`, a column from a `DataFrame` or a `Series`. The `null_count` method is a cheap operation as `null_count` is already calculated for the underlying Arrow array.\\n\\n\\nThe second piece of metadata is an array called a *validity bitmap* that indicates whether each data value is valid or missing.\\nThe validity bitmap is memory efficient as it is bit encoded - each value is either a 0 or a 1. This bit encoding means the memory overhead per array is only (array length / 8) bytes. The validity bitmap is used by the `is_null` method in Polars.\\n\\n\\nYou can return a `Series` based on the validity bitmap for a column in a `DataFrame` or a `Series` with the `is_null` method:\\n\\n\\n\\n\\n\\n \\n\\n```python\\n\\nis_null_series = df.select(\\n    pl.col(\"value\").is_null(),\\n)\\nprint(is_null_series)\\n\\n```\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe `is_null` method is a cheap operation that does not require scanning the full column for `null` values. This is because the validity bitmap already exists and can be returned as a Boolean array.', metadata={'_id': 94, '_collection_name': 'document_collection'}),\n",
       "  Document(page_content='Upsampling strategies\\n\\n\\nIn this example we upsample from the original 30 minutes to 15 minutes and then use a `forward` strategy to replace the nulls with the previous non-null value:\\n\\n\\n\\n\\n\\n \\n\\n```python\\n\\nout1 = df.upsample(time_column=\"time\", every=\"15m\").fill_null(strategy=\"forward\")\\nprint(out1)\\n\\n```\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIn this example we instead fill the nulls by linear interpolation:\\n\\n\\n\\n\\n\\n     \\n\\n```python\\n\\nout2 = (\\n    df.upsample(time_column=\"time\", every=\"15m\")\\n    .interpolate()\\n    .fill_null(strategy=\"forward\")\\n)\\nprint(out2)\\n\\n```', metadata={'_id': 313, '_collection_name': 'document_collection'})],\n",
       " 'answer': \"Sure, here's a detailed explanation of the `null_count` method:\\n\\nThe `null_count` method allows you to quickly and efficiently get the number of missing values in a column. It returns a DataFrame containing the number of missing values in each row of the input DataFrame.\\n\\nThe method can be called on a DataFrame, a column from a DataFrame, or a Series. It is a cheap operation as `null_count` is already calculated for the underlying Arrow array.\\n\\nYou can also return a Series based on the validity bitmap for a column in a DataFrame or a Series with the `is_null` method.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import langchainhub, please install with `pip install langchainhub`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/env/lib/python3.11/site-packages/langchain/hub.py:18\u001b[0m, in \u001b[0;36m_get_client\u001b[0;34m(api_url, api_key)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchainhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchainhub'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hub\n\u001b[0;32m----> 3\u001b[0m retrieval_qa_chat_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpull\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlangchain-ai/retrieval-qa-chat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/env/lib/python3.11/site-packages/langchain/hub.py:82\u001b[0m, in \u001b[0;36mpull\u001b[0;34m(owner_repo_commit, api_url, api_key)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpull\u001b[39m(\n\u001b[1;32m     68\u001b[0m     owner_repo_commit: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m     70\u001b[0m     api_url: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m     api_key: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     73\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    Pull an object from the hub and returns it as a LangChain object.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    :param api_key: The API key to use to authenticate with the LangChain Hub API.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43m_get_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(client, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpull_repo\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;66;03m# >= 0.1.15\u001b[39;00m\n\u001b[1;32m     86\u001b[0m         res_dict \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mpull_repo(owner_repo_commit)\n",
      "File \u001b[0;32m~/env/lib/python3.11/site-packages/langchain/hub.py:20\u001b[0m, in \u001b[0;36m_get_client\u001b[0;34m(api_url, api_key)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchainhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import langchainhub, please install with `pip install \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchainhub`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Client logic will also attempt to load URL/key from environment variables\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Client(api_url, api_key\u001b[38;5;241m=\u001b[39mapi_key)\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import langchainhub, please install with `pip install langchainhub`."
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
