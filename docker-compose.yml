services:
  ollama:
    image: ollama/ollama:latest
    volumes:
      - ./ollama/ollama:/root/.ollama
      - ./ollama_entrypoint.sh:/entrypoint.sh
    entrypoint: ["/usr/bin/bash", "/entrypoint.sh"]
    env_file: ".env"
    # ports:
    #   - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  server:
    build:
      context: ./backend
    ports:
      - "${SERVER_PORT}:${SERVER_PORT}"
    env_file: ".env"
    depends_on:
      weaviate-loader:
        condition: service_completed_successfully
      ollama:
        condition: service_started
      weaviate:
        condition: service_started
      alloy:
        condition: service_started


  weaviate-loader:
    depends_on:
      - weaviate
    build: 
      context: ./weaviate
    env_file:
      - .env

  ui:
    build:
      context: frontend
    ports:
      - "8070:8070"
    env_file: ".env"
    depends_on:
        - server

  weaviate:
    entrypoint: ["sh", "/entrypoint.sh"]
    image: cr.weaviate.io/semitechnologies/weaviate:1.25.4
    depends_on:
      - text-embeddings-inference
    ports:
    - "${WEAVIATE_PORT}:${WEAVIATE_PORT}"
    - "50051:50051"
    env_file:
      - .env
    volumes:
    - ./weaviate/entrypoint.sh:/entrypoint.sh
    - weaviate_data:/var/lib/weaviate
    #    restart: on-failure:0
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      ENABLE_MODULES: ''
      CLUSTER_HOSTNAME: 'node1'
      PROMETHEUS_MONITORING_ENABLED: 'true'

  text-embeddings-inference:
    ports:
      - ${TEI_PORT}:${TEI_PORT}
    volumes:
        - ./data:/data
    image: ghcr.io/huggingface/text-embeddings-inference:turing-1.5
    env_file:
      - .env
    command: --model-id $MODEL --pooling mean --port ${TEI_PORT}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                  - gpu
  
  jaeger:
    # env_file:
    #   - .env
    # container_name: jaeger
    ports:
        - 6831:6831/udp
        - 5778:5778
        - 16686:16686
        - 4318:4318
        - 4317:4317
        - 14269:14269
    image: jaegertracing/all-in-one:latest
  
  prometheus:
    # env_file:
    #   - .env
    ports:
      - "9090:9090"
    volumes:
      - ./Prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    image: prom/prometheus:latest
    command:
    - --config.file=/etc/prometheus/prometheus.yml
    - --web.enable-remote-write-receiver 
  
  grafana:
    depends_on:
      - prometheus
      - jaeger
    ports:
      - "3000:3000"
    image: grafana/grafana-oss

  alloy:
    image: grafana/alloy:latest
    volumes:
      - ./alloy/config.alloy:/etc/alloy/config.alloy
    ports:
      - "12345:12345"
    depends_on:
      - jaeger
      - prometheus
    command: 
    - run
    - --server.http.listen-addr=0.0.0.0:12345
    - --storage.path=/var/lib/alloy/data
    - --stability.level=experimental
    - /etc/alloy/config.alloy  


volumes:
  weaviate_data:


